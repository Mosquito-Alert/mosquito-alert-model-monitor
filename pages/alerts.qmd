---
title: "Alerts & Notifications"
format: html
---

```{r}
#| label: setup
#| include: false

library(shiny)
library(DT)
library(jsonlite)
library(lubridate)
library(dplyr)
library(purrr)
library(stringr)

# Function to load alerts
load_alerts <- function() {
  alerts_file <- "data/alerts/current_alerts.json"
  
  if (!file.exists(alerts_file)) {
    return(data.frame())
  }
  
  tryCatch({
    alerts <- fromJSON(alerts_file)
    if (is.data.frame(alerts) && nrow(alerts) > 0) {
      alerts$timestamp <- as.POSIXct(alerts$timestamp)
      return(alerts)
    } else {
      return(data.frame())
    }
  }, error = function(e) {
    return(data.frame())
  })
}

# Function to check for alert conditions
check_alerts <- function(jobs_data) {
  alerts <- data.frame()
  
  if (nrow(jobs_data) == 0) {
    return(alerts)
  }
  
  # Check for failed jobs
  failed_jobs <- jobs_data %>%
    filter(status == "failed") %>%
    mutate(
      alert_type = "job_failed",
      severity = "high",
      message = paste("Job", job_name, "has failed"),
      timestamp = Sys.time()
    )
  
  # Check for long-running jobs (> 2 hours)
  long_running <- jobs_data %>%
    filter(status == "running", !is.na(duration), duration > 7200) %>%
    mutate(
      alert_type = "long_running",
      severity = "medium", 
      message = paste("Job", job_name, "has been running for", 
                     round(duration/3600, 1), "hours"),
      timestamp = Sys.time()
    )
  
  # Check for jobs that haven't run recently (> 24 hours)
  current_time <- Sys.time()
  stale_jobs <- jobs_data %>%
    filter(!is.na(last_updated)) %>%
    mutate(
      hours_since_update = as.numeric(difftime(current_time, last_updated, units = "hours"))
    ) %>%
    filter(hours_since_update > 24) %>%
    mutate(
      alert_type = "stale_job",
      severity = "medium",
      message = paste("Job", job_name, "hasn't updated in", 
                     round(hours_since_update, 1), "hours"),
      timestamp = Sys.time()
    )
  
  # Combine all alerts
  all_alerts <- bind_rows(
    failed_jobs %>% select(job_name, alert_type, severity, message, timestamp),
    long_running %>% select(job_name, alert_type, severity, message, timestamp),
    stale_jobs %>% select(job_name, alert_type, severity, message, timestamp)
  )
  
  return(all_alerts)
}

# Load current job status
load_job_status <- function() {
  status_dir <- "data/status"
  if (!dir.exists(status_dir)) {
    return(data.frame())
  }
  
  json_files <- list.files(status_dir, pattern = "*.json", full.names = TRUE)
  
  if (length(json_files) == 0) {
    return(data.frame())
  }
  
  jobs_data <- map_dfr(json_files, function(file) {
    tryCatch({
      data <- fromJSON(file)
      data$last_updated <- file.info(file)$mtime
      data$config_file <- basename(file)
      return(data)
    }, error = function(e) {
      return(NULL)
    })
  })
  
  return(jobs_data)
}
```

## Current Alerts

```{r}
#| label: current-alerts

# Load job data and check for alerts
jobs_data <- load_job_status()
current_alerts <- check_alerts(jobs_data)

if (nrow(current_alerts) == 0) {
  cat("✅ **No active alerts** - All systems running normally\n\n")
} else {
  cat("⚠️ **Active Alerts:**", nrow(current_alerts), "alerts detected\n\n")
}
```

```{r}
#| label: alerts-table

if (nrow(current_alerts) > 0) {
  
  # Format alerts for display
  display_alerts <- current_alerts %>%
    mutate(
      Severity = case_when(
        severity == "high" ~ '<span class="badge badge-danger">HIGH</span>',
        severity == "medium" ~ '<span class="badge badge-warning">MEDIUM</span>',
        severity == "low" ~ '<span class="badge badge-info">LOW</span>',
        TRUE ~ '<span class="badge badge-secondary">UNKNOWN</span>'
      ),
      Type = case_when(
        alert_type == "job_failed" ~ "Job Failed",
        alert_type == "long_running" ~ "Long Running",
        alert_type == "stale_job" ~ "Stale Job",
        TRUE ~ alert_type
      ),
      Time = format(timestamp, "%Y-%m-%d %H:%M:%S")
    ) %>%
    select(
      Time,
      `Job Name` = job_name,
      Type,
      Severity,
      Message = message
    ) %>%
    arrange(desc(Time))
  
  DT::datatable(
    display_alerts,
    escape = FALSE,
    options = list(
      pageLength = 20,
      dom = 'tip',
      order = list(list(0, 'desc'))
    ),
    class = "table table-striped"
  )
} else {
  cat("No alerts to display.")
}
```

## Alert Configuration

The monitoring system automatically checks for the following conditions:

### Alert Types

1. **Job Failed (HIGH severity)**
   - Triggers when a job status is "failed"
   - Requires immediate attention

2. **Long Running Job (MEDIUM severity)** 
   - Triggers when a job has been running for more than 2 hours
   - May indicate performance issues or infinite loops

3. **Stale Job (MEDIUM severity)**
   - Triggers when a job hasn't updated its status in over 24 hours
   - May indicate the job has stopped unexpectedly

### Alert History

```{r}
#| label: alert-history

# Load historical alerts if available
alerts_history_file <- "data/alerts/alerts_history.json"

if (file.exists(alerts_history_file)) {
  
  tryCatch({
    alerts_history <- fromJSON(alerts_history_file)
    
    if (is.data.frame(alerts_history) && nrow(alerts_history) > 0) {
      
      # Show summary of recent alerts
      recent_alerts <- alerts_history %>%
        mutate(timestamp = as.POSIXct(timestamp)) %>%
        filter(timestamp >= Sys.time() - days(7)) %>%
        arrange(desc(timestamp))
      
      if (nrow(recent_alerts) > 0) {
        cat("### Recent Alerts (Last 7 Days)\n\n")
        
        alert_summary <- recent_alerts %>%
          group_by(alert_type, severity) %>%
          summarise(count = n(), .groups = "drop") %>%
          arrange(desc(count))
        
        DT::datatable(
          alert_summary,
          colnames = c("Alert Type", "Severity", "Count"),
          options = list(
            pageLength = 10,
            dom = 't'
          ),
          class = "table table-sm"
        )
      } else {
        cat("No alerts in the past 7 days.\n\n")
      }
    }
    
  }, error = function(e) {
    cat("Error loading alert history:", e$message, "\n\n")
  })
  
} else {
  cat("No alert history file found. Alert history will be available after alerts are generated.\n\n")
}
```

## Notification Configuration

To set up notifications for alerts, you can configure the following:

### Email Notifications
- Configure SMTP settings in `config/email_config.json`
- Set recipient email addresses for different alert severities

### Slack Integration
- Set up a Slack webhook URL in `config/slack_config.json` 
- Configure which alerts should be sent to Slack

### Custom Webhooks
- Configure custom webhook URLs in `config/webhook_config.json`
- Useful for integration with other monitoring systems

**Note:** Notification configurations are not yet implemented but can be added based on your requirements.
