---
title: "Alerts & Monitoring"
format: html
---

```{r setup, include=FALSE}
library(DT)
library(plotly)
library(jsonlite)
library(lubridate)
library(dplyr)
library(purrr)
library(stringr)
library(ggplot2)

# Source the shared functions
source("scripts/dashboard_functions.R")
```

# System Alerts & Monitoring

This page provides automated alerts and monitoring for job failures, performance issues, and system status.

```{r load-data, echo=FALSE, message=FALSE, warning=FALSE}
# Load current job status
jobs_data <- load_job_status()

# Load historical data for trend analysis
history_files <- list.files("data/history", pattern = "*.json", full.names = TRUE)
history_data <- data.frame()

if (length(history_files) > 0) {
  history_data <- map_dfr(history_files, function(file) {
    tryCatch({
      data <- fromJSON(file, flatten = TRUE)
      if (is.data.frame(data) && nrow(data) > 0) {
        data$date_file <- basename(tools::file_path_sans_ext(file))
        return(data)
      }
      return(data.frame())
    }, error = function(e) {
      data.frame()
    })
  })
  
  if (nrow(history_data) > 0) {
    history_data <- history_data %>%
      mutate(
        timestamp = as_datetime(timestamp),
        duration = as.numeric(duration),
        progress = as.numeric(progress),
        date_recorded = as.Date(date_file)
      )
  }
}

# Generate alerts
current_time <- Sys.time()
alerts <- list()
```

## ðŸš¨ Active Alerts

```{r active-alerts, echo=FALSE, message=FALSE, warning=FALSE}
if (nrow(jobs_data) > 0) {
  # Check for failed jobs
  failed_jobs <- jobs_data %>% filter(status == "failed")
  
  # Check for overdue jobs
  overdue_jobs <- jobs_data %>%
    filter(!is.na(next_scheduled_run)) %>%
    mutate(next_run = as_datetime(next_scheduled_run)) %>%
    filter(next_run < current_time & status != "running") %>%
    mutate(delay_hours = round(as.numeric(current_time - next_run) / 3600, 1))
  
  # Check for long-running jobs (>2 hours)
  long_running <- jobs_data %>%
    filter(status == "running", duration > 7200) %>%
    mutate(runtime_hours = round(duration / 3600, 1))
  
  # Check for high resource usage
  high_resource <- jobs_data %>%
    filter(cpu_usage > 90 | memory_usage > 8000) %>%
    mutate(
      high_cpu = cpu_usage > 90,
      high_memory = memory_usage > 8000
    )
  
  # Compile alerts
  alert_summary <- data.frame(
    Alert_Type = character(),
    Job_Name = character(), 
    Severity = character(),
    Description = character(),
    Action_Required = character(),
    stringsAsFactors = FALSE
  )
  
  # Add failed job alerts
  if (nrow(failed_jobs) > 0) {
    for (i in 1:nrow(failed_jobs)) {
      alert_summary <- rbind(alert_summary, data.frame(
        Alert_Type = "Job Failure",
        Job_Name = failed_jobs$job_name[i],
        Severity = "HIGH",
        Description = paste("Job failed at", failed_jobs$last_updated[i]),
        Action_Required = "Check logs and restart job",
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Add overdue job alerts
  if (nrow(overdue_jobs) > 0) {
    for (i in 1:nrow(overdue_jobs)) {
      severity <- if (overdue_jobs$delay_hours[i] > 24) "HIGH" else "MEDIUM"
      alert_summary <- rbind(alert_summary, data.frame(
        Alert_Type = "Overdue Job",
        Job_Name = overdue_jobs$job_name[i],
        Severity = severity,
        Description = paste("Job overdue by", overdue_jobs$delay_hours[i], "hours"),
        Action_Required = "Check job scheduler and system status",
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Add long-running alerts
  if (nrow(long_running) > 0) {
    for (i in 1:nrow(long_running)) {
      alert_summary <- rbind(alert_summary, data.frame(
        Alert_Type = "Long Running",
        Job_Name = long_running$job_name[i],
        Severity = "MEDIUM",
        Description = paste("Job running for", long_running$runtime_hours[i], "hours"),
        Action_Required = "Monitor progress and consider intervention",
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Add resource usage alerts
  if (nrow(high_resource) > 0) {
    for (i in 1:nrow(high_resource)) {
      issues <- c()
      if (high_resource$high_cpu[i]) issues <- c(issues, paste("CPU:", round(high_resource$cpu_usage[i], 1), "%"))
      if (high_resource$high_memory[i]) issues <- c(issues, paste("Memory:", round(high_resource$memory_usage[i], 0), "MB"))
      
      alert_summary <- rbind(alert_summary, data.frame(
        Alert_Type = "High Resource Usage",
        Job_Name = high_resource$job_name[i],
        Severity = "MEDIUM",
        Description = paste("High resource usage:", paste(issues, collapse = ", ")),
        Action_Required = "Monitor system performance",
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Display alerts table
  if (nrow(alert_summary) > 0) {
    DT::datatable(
      alert_summary,
      caption = paste("Active Alerts (", nrow(alert_summary), "total)"),
      options = list(
        pageLength = 10,
        order = list(list(2, 'desc')),  # Sort by severity
        columnDefs = list(
          list(className = 'dt-center', targets = '_all')
        )
      ),
      rownames = FALSE
    ) %>%
      DT::formatStyle(
        'Severity',
        backgroundColor = DT::styleEqual(
          c('HIGH', 'MEDIUM', 'LOW'),
          c('#ffebee', '#fff3e0', '#e8f5e8')
        )
      ) %>%
      DT::formatStyle(
        'Alert_Type',
        backgroundColor = DT::styleEqual(
          c('Job Failure', 'Overdue Job', 'Long Running', 'High Resource Usage'),
          c('#ffcdd2', '#ffe0b2', '#f8bbd9', '#dcedc1')
        )
      )
  } else {
    cat("âœ… **No active alerts** - All systems operating normally!\n\n")
  }
} else {
  cat("No job data available for alert monitoring.\n")
}
```

## ðŸ“Š System Health Overview

```{r system-health, echo=FALSE, message=FALSE, warning=FALSE}
if (nrow(jobs_data) > 0) {
  # Calculate system health metrics
  total_jobs <- nrow(jobs_data)
  running_jobs <- sum(jobs_data$status == "running")
  completed_jobs <- sum(jobs_data$status == "completed")
  failed_jobs <- sum(jobs_data$status == "failed")
  waiting_jobs <- sum(jobs_data$status == "waiting")
  
  # Overall system health score
  health_score <- round((completed_jobs + running_jobs) / total_jobs * 100, 1)
  
  # Create health summary
  health_summary <- data.frame(
    Metric = c("Total Jobs", "Running", "Completed", "Failed", "Waiting", "System Health Score"),
    Value = c(total_jobs, running_jobs, completed_jobs, failed_jobs, waiting_jobs, paste(health_score, "%")),
    Status = c(
      "Info", 
      if (running_jobs > 0) "Good" else "Info",
      if (completed_jobs > 0) "Good" else "Info", 
      if (failed_jobs > 0) "Warning" else "Good",
      "Info",
      if (health_score >= 90) "Excellent" else if (health_score >= 70) "Good" else "Warning"
    )
  )
  
  DT::datatable(
    health_summary,
    caption = "System Health Overview",
    options = list(
      pageLength = 10,
      columnDefs = list(
        list(className = 'dt-center', targets = '_all')
      )
    ),
    rownames = FALSE
  ) %>%
    DT::formatStyle(
      'Status',
      backgroundColor = DT::styleEqual(
        c('Excellent', 'Good', 'Warning', 'Info'),
        c('#e8f5e8', '#e3f2fd', '#fff3e0', '#f5f5f5')
      )
    )
}
```

## ðŸ“ˆ Performance Monitoring

```{r performance-monitoring, echo=FALSE, message=FALSE, warning=FALSE}
if (nrow(history_data) > 0) {
  # Recent performance trends (last 7 days)
  recent_data <- history_data %>%
    filter(timestamp >= (current_time - days(7)))
  
  if (nrow(recent_data) > 0) {
    # Failure rate trend
    daily_failures <- recent_data %>%
      mutate(date = as.Date(timestamp)) %>%
      group_by(date, job_name) %>%
      summarise(
        total_runs = n(),
        failures = sum(status == "failed"),
        failure_rate = round(failures / total_runs * 100, 1),
        .groups = 'drop'
      )
    
    # Plot failure rates
    if (nrow(daily_failures) > 0) {
      p_failures <- daily_failures %>%
        ggplot(aes(x = date, y = failure_rate, color = job_name)) +
        geom_line(size = 1) +
        geom_point(aes(size = total_runs)) +
        scale_y_continuous(limits = c(0, max(100, max(daily_failures$failure_rate, na.rm = TRUE)))) +
        theme_minimal() +
        labs(
          title = "Job Failure Rate - Last 7 Days",
          x = "Date",
          y = "Failure Rate (%)",
          color = "Job Name",
          size = "Total Runs"
        )
      
      ggplotly(p_failures, tooltip = c("x", "y", "colour", "size"))
    }
  }
}
```

## ðŸ”§ Maintenance Recommendations

```{r maintenance-recommendations, echo=FALSE, message=FALSE, warning=FALSE}
recommendations <- data.frame(
  Priority = character(),
  Recommendation = character(),
  Reason = character(),
  stringsAsFactors = FALSE
)

if (nrow(jobs_data) > 0) {
  # Check for jobs that haven't run recently
  stale_jobs <- jobs_data %>%
    mutate(last_updated_time = as_datetime(last_updated)) %>%
    filter(last_updated_time < (current_time - hours(24))) %>%
    mutate(hours_since = round(as.numeric(current_time - last_updated_time) / 3600, 1))
  
  if (nrow(stale_jobs) > 0) {
    for (i in 1:nrow(stale_jobs)) {
      recommendations <- rbind(recommendations, data.frame(
        Priority = "Medium",
        Recommendation = paste("Check", stale_jobs$job_name[i], "job status"),
        Reason = paste("No updates for", stale_jobs$hours_since[i], "hours"),
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Check for consistently slow jobs
  if (nrow(history_data) > 0) {
    slow_jobs <- history_data %>%
      filter(timestamp >= (current_time - days(7))) %>%
      group_by(job_name) %>%
      summarise(
        avg_duration = mean(duration, na.rm = TRUE),
        median_duration = median(duration, na.rm = TRUE),
        .groups = 'drop'
      ) %>%
      filter(avg_duration > 3600)  # More than 1 hour average
    
    if (nrow(slow_jobs) > 0) {
      for (i in 1:nrow(slow_jobs)) {
        recommendations <- rbind(recommendations, data.frame(
          Priority = "Low",
          Recommendation = paste("Optimize", slow_jobs$job_name[i], "performance"),
          Reason = paste("Average runtime:", round(slow_jobs$avg_duration[i]/60, 1), "minutes"),
          stringsAsFactors = FALSE
        ))
      }
    }
  }
  
  # General maintenance recommendations
  recommendations <- rbind(recommendations, data.frame(
    Priority = "Low",
    Recommendation = "Review log files for any warning messages",
    Reason = "Regular maintenance best practice",
    stringsAsFactors = FALSE
  ))
  
  recommendations <- rbind(recommendations, data.frame(
    Priority = "Low", 
    Recommendation = "Archive old historical data (>30 days)",
    Reason = "Optimize dashboard performance",
    stringsAsFactors = FALSE
  ))
}

if (nrow(recommendations) > 0) {
  DT::datatable(
    recommendations,
    caption = "System Maintenance Recommendations",
    options = list(
      pageLength = 10,
      columnDefs = list(
        list(className = 'dt-center', targets = '_all')
      )
    ),
    rownames = FALSE
  ) %>%
    DT::formatStyle(
      'Priority',
      backgroundColor = DT::styleEqual(
        c('High', 'Medium', 'Low'),
        c('#ffebee', '#fff3e0', '#e8f5e8')
      )
    )
} else {
  cat("No maintenance recommendations at this time.\n")
}
```

## ðŸ“§ Alert Configuration

```{r alert-config, echo=FALSE, message=FALSE, warning=FALSE}
# Display current alert thresholds
alert_config <- data.frame(
  Alert_Type = c(
    "Job Failure",
    "Overdue Jobs", 
    "Long Running Jobs",
    "High CPU Usage",
    "High Memory Usage",
    "System Health Score"
  ),
  Threshold = c(
    "Any failed status",
    "> 1 hour past scheduled time",
    "> 2 hours runtime",
    "> 90% CPU usage",
    "> 8GB memory usage", 
    "< 70% overall health"
  ),
  Current_Action = c(
    "Display alert in dashboard",
    "Display alert in dashboard",
    "Display alert in dashboard", 
    "Display alert in dashboard",
    "Display alert in dashboard",
    "Display alert in dashboard"
  )
)

DT::datatable(
  alert_config,
  caption = "Alert Configuration & Thresholds",
  options = list(
    pageLength = 10,
    columnDefs = list(
      list(className = 'dt-center', targets = '_all')
    )
  ),
  rownames = FALSE
)
```

---

*Page last updated: `r Sys.time()`*

**Note**: This monitoring system provides basic alerting through the dashboard. For production use, consider integrating with external alerting systems (email, Slack, etc.) for immediate notifications.
